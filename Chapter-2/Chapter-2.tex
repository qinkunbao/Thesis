% !TEX root = ../YourName-Dissertation.tex

\chapter{Background and Related Work}\label{chapter2}

\section{Address-based Side-channel Attacks}
Side channels can leak sensitive information
unconsciously through different execution behaviors caused by shared 
hardware components (e.g., CPU cache, TLB, and
DRAM) in modern computer systems~\cite{ge2018survey,szefer2019survey}. 

For example, cached-based
side-channels~\cite{yarom2017cachebleed,191010,184415,Osvik2006,liu2015last,184415}
rely on the time difference between cache misses and cache hits. We introduce two
common attack strategies, namely Prime+Probe~\cite{liu2015last} and
Flush+Reload~\cite{184415}. Prime+Probe targets a single cache set. An
attacker preloads the cache set with its own data and waits until the victim
executes the program. If the victim accesses the cache set and evicts part of
the data, the attacker will experience a slow measurement. 
While Flush+Reload targets a
single cache line, it requires the attacker and victim share some memory. 
During the ``flush'' stage, the attacker flushes the ``monitored
memory'' from the cache and waits for the victim to access the memory,
who will load the sensitive information to the cache line. In the next phase,
the attacker reloads the ``monitored memory''. By measuring the time difference
brought by cache hit and miss, the attacker can further infer the sensitive information.
Some other types of side-channels target different hardware
layers other than CPU cache. For example, the controlled-channel
attack~\cite{7163052}, where an attacker works in the kernel space, can infer
sensitive data in shielding systems by observing the page fault sequences
after restricting some code and data pages.

\begin{figure}[]

    \noindent\begin{minipage}{0.45\linewidth}
        \noindent
        \begin{lstlisting}[numbers = none]
unsigned long long r;
int secret[32];
...
while(i>0){
    r = (r * r) % n;
    if(secret[--i] == 1)
        r = (r * x) % n;   
}
        \end{lstlisting}
\vspace*{-9pt}
        \caption{Secret-dependent control-flow transfers}
        \label{fig:secret:cf}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\linewidth}
        \begin{lstlisting}[numbers = none]
static char Fsb[256] = {...}
... 
uint32_t a = *RK++ ^ \ 
(FSb[(secret)) ^
(FSb[(secret >> 8)] << 8 ) ^
(FSb[(secret >>16)] << 16 ) ^
(FSb[(secret >>24)] << 24 );
...
        \end{lstlisting}
\vspace*{-9pt}
        \caption{Secret-dependent memory accesses}
        \label{fig:secret:da}
    \end{minipage}
\vspace*{-12pt}
\end{figure}

The key intuition is that above side-channel attacks happen when a
program accesses different memory addresses if the program has different
sensitive inputs. As shown in Figure~\ref{fig:secret:cf} and Figure~\ref{fig:secret:da}, 
if a program shows different patterns in
control transfers or data accesses when the program processes different
sensitive inputs, the program could possibly have side channels vulnerabilities.
Different kinds of side-channels can be exploited to retrieve information in
various granularities. For example, cache channels can observe cache
accesses at the level of cache sets~\cite{liu2015last}, cache lines~\cite{184415} or other granularities. 
Other kinds of side-channels like controlled-channel attack~\cite{7163052},
can observe the memory access at the level of memory pages.

\subsection{Cache-level Channel}
Cache-based channels rely on the time difference between cache misses and cache hits. Cache channel attacks can observe cache accesses at the level of cache sets, cache lines or other granularities. 
We introduce two common attack strategies, namely Prime+Probe and
Flush+Reload. Prime+Probe targets a single cache set. An
attacker preloads the cache set with its own data and waits until the victim
executes the program. If the victim accesses the cache set and evicts part of
the data, the attacker will experience a slow measurement. 
While Flush+Reload targets a single cache line, it requires the attacker and victim share some memory. During the ``flush'' stage, the attacker flushes the ``monitored
memory'' from the cache and waits for the victim to access the memory,
who will load the sensitive information to the cache line. In the next phase,
the attacker reloads the ``monitored memory''. By measuring the time difference
brought by cache hit and miss, the attacker can further infer the sensitive information. Some other types of side-channels target different hardware
layers other than CPU cache.

\subsection{Page-level Channel}
Recent studies also shows the attacks can observe the memory access at the granularity of memory pages. One example is the controlled-channel attack~\cite{xu2015controlled}, where a privileged adversary try to infer the sensitive information by manipulating the enclave page access. Those kinds of attacks usually happen on the shielding system. A malicious OS can proactively revoke a virtual enclave memory page from the memory. If the victim enclave program accesses the memory table, then the adversary can know which page is accessed by observing the page fault sequence. While the granularity of the controlled-channel attacks is very coarse grained, the controlled-channel attacks allow the attacker to have a noise-free observation. Examples of other attacks exploits page cache maintained by the OS, TLB also shares the same granularity.


In this paper, we consider three types of granularity: byte (1 Byte), cache line size (64 Bytes), page size (4 KBs). To the best of our knowledge, the three types of granularities can cover most of the side-channel attacks in literature.

\begin{table}
    \centering
    \caption{Due to the page limit, we only shows some representations of the vast side-channel attacks: Attacks, the shared hardware resources with attackers, the granularity of the attacker can observe, is there any published attacks on non-cryptography library and if the type of attack can exploit multiple leakage sites.}
    \label{table:side_channel_attack}
    \resizebox{\columnwidth}{!}{%
    
    \begin{tabular}{lllcc}
    \toprule
    Attacks & Shared Resources & Granularity  & Non-Crpyto & Multiple   \\ \midrule
    CacheBleed~\cite{yarom2017cachebleed} & Cache & Sub Cache Line (<64 B)  & \xmark & \xmark \\ 
    CopyCat~\cite{moghimi2020copycat} & Page Tables   & Instruction   & \xmark &  \xmark \\
    Prime + Probe~\cite{liu2015last} & Cache & Cache Set (64-512 B)  & \cmark &   \xmark \\
    Prime + Abort~\cite{disselkoen2017prime+} & Cache  & Cache Set (64-512 B) & \cmark &  \xmark   \\
    Flush + Reload~\cite{yarom2014flush+} & Cache & Cache Line (64 B) & \cmark  &  \cmark \\
    Flush + Flush~\cite{gruss2016flush+} & Cache & Cache Line (64 B) & \cmark & \xmark  \\
    Controlled-channel Attack~\cite{xu2015controlled} & Page Tables & Page (4KB) & \cmark & \xmark \\
    TLBleed~\cite{gras_translation_2018} & MMUs & TLB Set (4KB) & \cmark  & \xmark \\
    Page Cache Attacks~\cite{gruss2019page} & Page Cache &  Page (4KB) & \xmark &  \cmark \\ 
    \bottomrule
    \end{tabular}
    }
    \end{table}
\section{Information Theory}
This section presents a short introduction on information theory. For a detailed tutorial, we recommend users refer to the following literature.

Given an event $e$ that occurs with the probability $p(e)$, we receive
\begin{displaymath}
    I = - \log_2p(e)
\end{displaymath}
bits of information by knowing the event $e$ happens according to information theory~\cite{shannon1948mathematical}. 
Considering a char variable $a$
with one byte storage size in a C program, its value ranges from 0 to 255.
Assume $a$ has a uniform distribution. If we observe that
$a$ equals $1$, the probability of this observation is $\frac{1}{256}$. So 
we get $-\log(\frac{1}{256}) = 8$ bits information, which is exactly the size
of a char variable in the C program.

Existing works on information leakage quantification typically use Shannon
entropy~\cite{clark2007static,Wichelmann:2018:MFF:3274694.3274741},
min-entropy~\cite{10.1007/978-3-642-00596-1_21}, and max-entropy~\cite{182946,
Doychev:2017:RAS:3062341.3062388}. In these frameworks, the input sensitive
information $K$ is considered as a random variable.

Let $k$ be one of the possible
value of $K$. The Shannon entropy $H(K)$ is defined as
\begin{displaymath}
    H(K) = - \sum_{k {\in} K}p(k)\log_2(p(k))
\end{displaymath}

Shannon entropy can be used to quantify the initial uncertainty about the
sensitive information. It measures the amount of information in a system.

Min-entropy describes the information leaks for a program with the most likely input. 
For example, min-entropy can be used to describe the
best chance of success in guessing one's password using the
most common password. %, which is defined as
\begin{displaymath}
    \mathit{min\text{-}entropy} = - \log_2(p_{\mathit{max}})
\end{displaymath}

Max-entropy is defined solely on the number of possible observations.
%It is equal to $-\log_2{n}$.
\begin{displaymath}
    \mathit{max\text{-}entropy} = -\log_2{n}
\end{displaymath}
As it is easy to compute, most recent works~\cite{182946,Doychev:2017:RAS:3062341.3062388} use max-entropy as the definition of
the amount of leaked information.

To illustrate how these definitions work, we consider the code
fragment in Figure~\ref{fig:side-channel}. It has two secret-dependent
control-flows, A and B.

\begin{figure}[h!]
\centering
\begin{lstlisting}[xleftmargin=.03\textwidth,xrightmargin=.01\textwidth]
uint8_t key[2], t1, t2;
get_key(key);              // 0 <= key[0], key[1] < 256
t1 = key[0] + key[1];
t2 = key[0] - key[1];
if (t1 < 4){               // leakage site A
    foo();    
}                          
if (t2 > 0){               // leakage site B     
    doo();    
}                          
\end{lstlisting}
\vspace*{-1pt}
    \caption{Side-channel leakage}
    \label{fig:side-channel}
\end{figure}
In this paper we assume an attacker can observe the secret-dependent control-flows in Figure~\ref{fig:side-channel}.
Therefore, an attacker can have two different observations for each leak site
depending on the value of the $\mathit{key}$: $A$ for function \textsf{foo} is executed, 
$\neg A$ for function \textsf{foo} is not executed, $B$ for function \textsf{doo} is
executed, and $\neg B$ for function \textsf{doo} is not executed. Now the
question is how much information can be leaked from the above code if an
attacker knows which branch is executed?

\begin{table}[ht]
    \centering\small\footnotesize
    \caption{The distribution of observation}\label{shtable}
    \vspace*{-0pt}
%    \resizebox{\columnwidth}{!}{
    \begin{tabular}{l|cc|cc}
        \hline

        Observation ($o$)   & $A$ & $\neg A$ & $B$ & $\neg B$ \\ \hline
        Number of Solutions & 65526       & 10        & 32768     & 32768           \\ \hline
        Possibility (p)     & 0.9998      & 0.0002    & 0.5    & 0.5       \\
        \hline
    \end{tabular}
%        }
\end{table}

Assuming $\mathit{key}$ is uniformly distributed, we can calculate the corresponding
possibility by counting the number of possible inputs. Table~\ref{shtable}
describes the probability of each observation. We use the above three types of 
leakage metrics to calculate the amount of leaked information for leak A and leak B.

\vspace{3pt}
\textbf{Min Entropy.}
As $p_{A\mathit{max}} = 0.9998$ and $p_{B\mathit{max}} = 0.5$, 
with the definition, min-entropy equals to
\begin{align*}
    \mathit{min\text{-}entropy_A} & = -\log_2{0.9998} = 0.000\ \mathrm{bits} \\
    \mathit{min\text{-}entropy_B} & = -\log_2{0.5} = 1.000\ \mathrm{bits}
\end{align*}

\textbf{Max Entropy.}
Depending on the value of key, the code can run two different branches for each leakage site. 
Therefore, with the max entropy
definition, both leakage sites leak

\begin{displaymath}
    \mathit{max\text{-}entropy} = -\log_2{2} = 1.000\ \mathrm{bits}
\end{displaymath}

\textbf{Shannon Entropy.}
Based on Shannon entropy, the respective amount of information in A and B equals to
{\footnotesize
\begin{align*}
    \mathit{Shannon\text{-}entropy_A} & = -(0.9998*\log_{2}0.9998      \\
                                    & \qquad+ 0.0002*\log_{2}0.0002)  \\
                                    & = 0.000\ \mathrm{bits}         \\
    \mathit{Shannon\text{-}entropy_B} & = -(0.5*\log_{2}0.5      \\
                                    & \qquad+ 0.5*\log_{2}0.5)        \\
                                    & = 1.000\ \mathrm{bits}                             
\end{align*}
}
In the next section, we will show that these measures work well only
theoretically in a static analysis setting. 
Generally, they do not apply to dynamic analysis or real
settings. We will present that the static or theoretical results could be
dramatically different from the real world, and we do need a better method to
quantify the information leakage from a practical point of view.


Let $k$ be one of the possible
value of $K$. The Shannon entropy $H(K)$ is defined as
\begin{equation}\label{eq1}
    H(K) = - \sum_{k {\in} K}p(k)\log_2(k)
\end{equation}

Shannon entropy can be used to quantify the initial uncertainty about the sensitive information. It measures the amount of information in a system. For example, an AES encryption program takes a 128-bit key as the input. Suppose every key has the equal opportunity and $p_k = 1/ 2^{128}$, then the encryption system has $128 \, \mathit{bits}$ information according to Shannon entropy. 


In the paper, we use the channel capacity to describe the information leakages through a channel. In information theory, the channel capacity is used to quantify the rate of information can be reliably transmitted over a channel. If we use $K$ to represent the input secrets and $O$ to represent the output observation. The channel capacity ($C$) is defined as 

\begin{equation}\label{eq2}
C(K;O) = \max_{p(x)} I(K;O)
\end{equation}
Here $I(K;O)$ is the mutual information between $K$ and $O$.  
\begin{equation} \label{eq3}
    I(K;O) = \sum_{k {\in} K}{\sum_{o {\in} O}{p(k, o)\log_2\frac{p(k, o)}{p(k)p(o)}}}
\end{equation}

While the general case of channel capacity is hard to execute, we consider the two special channels.

\subsection{Noiseless Lossless Channel}
The channel of the system is noiseless and lossless if

\begin{equation} \label{eq:1}
    C(K;O) = \max_{p(k)} I(K;O) = \max_{p(k)} H|O| =\max_{p(k)} H|K|
\end{equation}
$|K|$ represents the number of symbols in $K$. 

Figure~\ref{fig:channel}a shows the example of the type of the channel. Under the circumstance, we always have $P(o_i/k_i) = 1$ and $P(k_i/o_i) = 1$. As we can see, the channel have the unique output ($o \in O$) for every input ($k \in K$). 

\begin{figure}
    \begin{minipage}{0.48\linewidth}
    \resizebox{\linewidth}{!}{
    
     \begin{tikzpicture}[ele/.style={fill=black,circle,minimum width=.8pt,inner sep=1pt},every fit/.style={ellipse,draw,inner sep=-2pt}]
      \node[ele,label=left:{\normalsize $k_1$}] (a1) at (0,4) {};    
      \node[ele,label=left:{\normalsize $k_2$}] (a2) at (0,3) {};    
      \node[ele,label=left:{\normalsize $k_3$}] (a3) at (0,2) {};
      \node[ele,label=left:{\normalsize $k_4$}] (a4) at (0,1) {};
    
      \node[ele,,label=right:{\normalsize $o_1$}] (b1) at (4,4) {};
      \node[ele,,label=right:{\normalsize $o_2$}] (b2) at (4,3) {};
      \node[ele,,label=right:{\normalsize $o_3$}] (b3) at (4,2) {};
      \node[ele,,label=right:{\normalsize $o_4$}] (b4) at (4,1) {};
    
      \node[draw,fit= (a1) (a2) (a3) (a4),minimum width=2cm] {} ;
      \node[draw,fit= (b1) (b2) (b3) (b4),minimum width=2cm] {} ;  
      \draw[->,thick,shorten <=2pt,shorten >=2pt] (a1) -- (b1);
      \draw[->,thick,shorten <=2pt,shorten >=2] (a2) -- (b2);
      \draw[->,thick,shorten <=2pt,shorten >=2] (a3) -- (b3);
      \draw[->,thick,shorten <=2pt,shorten >=2] (a4) -- (b4);
     \end{tikzpicture}
    }
    \caption*{(a) Noiseless Lossless}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\linewidth}
    \resizebox{\linewidth}{!}{
    
     \begin{tikzpicture}[ele/.style={fill=black,circle,minimum width=.8pt,inner sep=1pt},every fit/.style={ellipse,draw,inner sep=-2pt}]
      \node[ele,label=left:{\normalsize $k_1$}] (a1) at (0,4) {};    
      \node[ele,label=left:{\normalsize $k_2$}] (a2) at (0,3) {};    
      \node[ele,label=left:{\normalsize $k_3$}] (a3) at (0,2) {};
      \node[ele,label=left:{\normalsize $k_4$}] (a4) at (0,1) {};
    
      \node[ele,,label=right:{\normalsize $o_1$}] (b1) at (4,4) {};
      \node[ele,,label=right:{\normalsize $o_2$}] (b2) at (4,3) {};
      \node[ele,,label=right:{\normalsize $o_3$}] (b3) at (4,2) {};
      \node[ele,,label=right:{\normalsize $o_4$}] (b4) at (4,1) {};
    
      \node[draw,fit= (a1) (a2) (a3) (a4),minimum width=2cm] {} ;
      \node[draw,fit= (b1) (b2) (b3) (b4),minimum width=2cm] {} ;  
      \draw[->,thick,shorten <=2pt,shorten >=2pt] (a1) -- (b1);
      \draw[->,thick,shorten <=2pt,shorten >=2] (a2) -- (b2);
      \draw[->,thick,shorten <=2pt,shorten >=2] (a3) -- (b2);
      \draw[->,thick,shorten <=2pt,shorten >=2] (a4) -- (b2);
     \end{tikzpicture}
     }
     \caption*{(b) Noiseless Loss}
     \end{minipage}
    \caption{Two Kinds of Channels}\label{fig:channel}
    \end{figure}
    

\subsection{Noiseless Loss Channel}
In reality, noiseless loss channel is more common. We define the channel is noiseless loss if

\begin{equation} \label{eq:2}
    C(K;O) = \max_{p(x)} I(K;O) = \max_{p(x)} H |O| = \log_2 {|O|}
\end{equation}

Figure~\ref{fig:channel}b  shows the example of the type of the channel. Once the input symbol is determined, the output symbol is also determine. As we can see, the channel have the unique output ($o \in O$) for every input ($k \in K$).

\section{Binary Analysis}
Binary analysis is the process of automatically inferring program behaviors from
the binary executable.
It plays a critical role from a security viewpoint. For many programs, like malware, Commercial off-the-shelf (COTS) application, source code are typically not
available. Besides, some low-level information, including memory accesses and cache
accesses, is only available on the binary code level. As many side-channel vulnerabilities
are typically low-level problem, we believe binary analysis are more suitable than
source code level analysis.

Binary analysis can be categorized into two groups depending when the analysis is
launched.
\begin{itemize}
    \item Static Analysis infer analyzing the binary program without running it. Previous studies focus on addressing several open problems, including identifying
    function entry points~\cite{184521, Wang17a}, resolving indirect jumps, disambiguating code and data and solving alias memory address. Static analysis
    lacks the run-time information, which may lead to false positives and false 
    negatives. However, static analysis typically can have better coverage as it can
    reason about every possible execution paths.
    \item Dynamic Analysis involving analyzing a binary code as it executes. Tools
    that perform dynamic analysis usually need to instrument the binary code.  
    Although dynamic analysis can only reason only one execution path. It is usually more precise than static analysis.
\end{itemize}

In this dissertation, we detected side-channel vulnerabilities by trace-based analysis.
It consists of two steps. The first step, called online trace logging, collect run-time
information for the targeted program under the dynamic binary instrumentation (DBI)
to collect necessary information. The second step, called offline analysis, run
several analysis (e.g., taint analysis, symbolic analysis) on the top of traces.  

Existing binary analysis frameworks, like Angr, BAP and Bitblaze combine both static
and dynamic analyses, are applicable to a series of tasks. However, those frameworks
are not suitable for the following reasons. 
\begin{itemize}
    \item Existing binary analysis frameworks transfer the machine code into
    architecture-independent intermediate representatives (IR) and then run the
    analysis. The IR design, which simplify the implementation and support multiple
    architectures, introduces imprecision to the analysis results as well because some
    information like cache accesses, control-flow transfers are lost during the IR
    transformation.
    \item Coverage is one of the concerns when they design the frameworks. 
    As a result, they rely on constraint solvers to find different inputs that can
    trigger different paths. As constraint solving is known for time-consuming. It is
    one of the obstacles to make analyses salable.
    However, we will show for many tasks, like binary similarity comparisons and side-channel vulnerability detection. We can
    reduce the call to the solver just by fuzzing the formula. The design will
    significantly reduce the overhead.
\end{itemize}
To solve the above problem, we propose Phoenix, a trace-oriented binary analysis
framework. Phoenix is a dynamic binary analysis framework that provide several 
functioning including dynamic symbolic execution engine, dynamic taint analysis
engine, AST representation of X86 and binding for STP solvers. It run 
execution on the top X86 instructions and symbolically reason the program behaviours.
Our preliminary results show that Phoenix has a better performance compared to 
many existing works, which makes it scalable to real-world applications.
