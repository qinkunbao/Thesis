% !TEX root = ../YourName-Dissertation.tex

\chapter{Fast and Precise Side-channel Vulnerability Detection}\label{chapter3}
\section{Problem}
Side-channel attacks allow an attacker to infer sensitive information such as cryptographic keys, personal data from software products unconsciously. Based on the discussions in \S\ref{chapter1} and \S\ref{chapter2}, patching leakage sites in software is usually easier than adopting new hardware to defend against side-channel attacks. In order to eliminate those leakage sites, developers often need to identify potential leakage sites from the code base manually. However, the manual process is tedious and error-prone. Recent studies~\cite{203878} also suggest fixing old vulnerabilities can sometimes introduce new leakages.

Recent work has made good progress in identifying side-channel leakages automatically. Some tools (e.g., CacheD, CaSym) have successfully identified unknown leakage sites from software products automatically. However, those tools have the following limitations.

First, although some tools can find side-channel leakages in real-world software products, they can only analyze one code fragment at a time due to the expensive performance overhead. As a result, users of those tools sometimes need to manually cut off some irrelevant code based on their past experience. The trimming process is tedious and needs domain knowledge of the target software (e.g., which part of the code is more likely to have side-channel leakage sites). More importantly, if many leakages sites are on the trimmed code, those tools will miss those leakage sites as well.

Second, many tools perform the analysis at the level of intermediate representations (IR) instead of machine code. It is a design decision to facilitate the implementations. While analyzing the IRs can simplify the implementation, it is not a suitable design choice for the side-channel analysis. In reality, side-channel leakages are a pretty low-level issue and only the low-level analysis can give the most accurate results. For example, the IR-level branches is not necessarily a superset or a subset of machine-code level branches. Besides, compiler optimizations can eliminate the IR-level branches like conditional moves and the converse could also happen. Moreover, translating the machine code into IRs can cause a significant overhead for the trace analysis, as we will discuss in the dissertation.

To overcome the above problems, we propose a fast and precise method to detect the side-channel leakages in real-world software products. Different from previous methods, our tool analyzes on the machine code, which can give more precision than traditional IR-based approaches.  We examine the bottleneck of current symbolic execution approaches and optimize it to work on real-world cryptography systems. The evaluation results show that our tool can identify previous side-channel leakages, as well as find new leakages. Compared to recent tools, our tool is 3-100x faster while finding all the leakages when we evaluate on the same benchmarks.

\section{Background and Threat Model}
\subsection{Micro-architectures}
Many side-channel attacks are architecture-dependent. To facilitate the illustration, we present some necessary backgrounds in this section.

CPUs process data in a much faster speed than the main memory (DRAM) can supply. Modern CPUs adopt a hierarchy memory to bridge the performance gap between the CPUs and the main memory. By storing extra copies of data and code in a smaller but faster memory, the software can get its most recently accessed code and data in a shorter time.

Figure~\ref{fig:memory_hierarchy} shows the overview of the hierarchy memory. For a CPU with multiple cores, each core has two private level-1 (L1) cache, an instruction cache (iCache), and a data cache (dCache). Because instructions and data have different access patterns, separating iCache and dCache makes it possible for CPUs to fetch the code and data and improve performance simultaneously. Followed by the level-1 cache, each core also has the unified private level-2 cache for both the code and the data. The level-3 cache is the last level cache (LLC). The LLC is shared among all the cores. The main memory is the bottom-most under the memory hierarchy.
\begin{figure}
  \centering
  \includegraphics[width=.5\columnwidth]{./figures/chapter3/architecture.pdf}
  \caption{Computer memory hierarchy. The hierarchy is designed to minimise the access time with the relatively low cost. It is the root cause of many side-channel attacks.}\label{fig:memory_hierarchy}
\end{figure}

The current computer memory hierarchy opens the way for side-channel attacks from two aspects. First, the architecture relies on the system software for managing the memory, which becomes a problem in a threat model where the operating system is not untrusted (e.g., Intel SGX). Second, the size of the cache is smaller than the main memory. It is possible that different units in the main memory share the same address in the cache.
\begin{figure}
  \centering
  \includegraphics[width=.65\columnwidth]{./figures/chapter3/address.pdf}
  \caption{Memory addressing}\label{fig:memory_address}
\end{figure}

In modern CPUs, L1 and L2 caches are traditional N-way set associate caches. That is, the cache is divided into several cache sets, and each set is associated with several cache lines. The cache line is the atomic unit. As shown in Figure~\ref{fig:memory_address}, we can determine whether the data is in the cache with the following steps.  Given an address, the CPU uses the \textsf{Set Index} field of the address to locate the cache set that the address should reside in. After that, it tries to use the \textsf{Tag} field to match every cache line inside the set line. If the CPU can locate a cache line with the same tag and the valid bit is set, then a cache hit occurs. The CPUs use a similar process to manage the main memory. The main memory is divided into many units called pages. As shown in Figure~\ref{fig:memory_address},
the translation process keeps the bottom bits same while using the top bits to map the Physical Page Numbers to Virtual Page Numbers.

\subsection{Threat Model}
We assume that an attacker shares the same hardware platform with the target.
The attacker attempts to retrieve sensitive information through address-based
side-channel attacks. The attacker has no direct access to the target's memory or cache,
but it can probe its memory or cache at each program point. Here are a few examples.
\begin{enumerate}
  \item A host machine has several Virtual Machines (VMs). The victim runs the application inside one VM. An attacker can control the VM and probe the process running on the other VM.
  \item  In a shielding system, a malicious operating system can extract sensitive information from the protected application.
  \item An user level application can probe some sensitive information inside the kernel.
\end{enumerate}

In reality, the
attacker will face many possible obstacles such as the noisy observations of the memory or cache. However, for this project, we assume
the attacker has noise-free observations as in previous work~\cite{203878,182946,Brotzman19Casym}.
The threat model captures most address-based side-channel attacks and apply to the three attack models: 1) time-based attacks, 2) access-based attacks, 3) trace-based attacks. We only consider deterministic programs and assume an attacker has access to the source code or binary executable of the target program.

\section{Limitations of Current Side-channel Leakage Detection Tools}
In this section, we introduces two limitations of current side-channel leakage detection method. The first limitation is that some tools may have some false positives or false negatives. The second limitation is the current tools are not fast enough to analyze real world side-channel leakages.


\subsection{Imprecision}
In this dissertation, we study two types of side-channel leakage code patterns. The key intuition is that the target application shows different control flows or data flows when it processes different sensitive input data. We refer them as secret-dependent control flow transfers and secret-dependent data accesses. Unlike previous work, our tool works on the machine code, which can provide us more prevision than the previous tools.
\subsubsection{Control Flow}
\begin{figure}[h]
  \begin{minipage}{0.45\linewidth}
    \begin{lstlisting}[xleftmargin=.0\textwidth, xrightmargin=.0\textwidth, frame=none]
int example1(uint8_t k, uint32_t m) { // m = 0
  uint32_t b = (k & m) >> 7;
  if (b) {
    ...    // Branch 1
  } else {
    ...    // Branch 2
  }
  ...
}
\end{lstlisting}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\linewidth}
    \begin{lstlisting}[xleftmargin=.0\textwidth, xrightmargin=.00\textwidth, frame=none, numbers=none, mathescape=true]
push  ebp
mov   ebp, esp
movzx eax, [addr_k]    
and   eax, [addr_me] 
shr   eax, 0x7           
test  eax, eax
jne   branch 2
...
\end{lstlisting}
  \end{minipage}\caption*{(a) A False Negative}

  \begin{minipage}{0.45\linewidth}
    \begin{lstlisting}[xleftmargin=.0\textwidth, xrightmargin=.0\textwidth, frame=none]
int example2(uint16_t k) {
  int res;
  if (k > 8) {
    res = 0;
  } else {
    res = 1;
  }
  return res;
}
\end{lstlisting}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\linewidth}
    \begin{lstlisting}[xleftmargin=.0\textwidth, xrightmargin=.00\textwidth, frame=none, numbers=none, mathescape=true]
xor   eax, eax
cmp   [addr_k], 8
setbe  al
xor    edx, edx
ret
\end{lstlisting}
  \end{minipage}\caption*{(b) A False Positive}
  \caption{Secret-dependent Control-flow Transfers}\label{fig:chapter3:cf}
\end{figure}

If the input-sensitive data can affect the victim program's control flow, then an attacker can infer the sensitive data by observing the control flow during the execution. Figure~\ref{fig:chapter3:cf}(a) shows such an example. The function takes a public value \textsf{m} and a secret \textsf{k} as the input values. The code at line 2 ensures that the lower 7 bits of the value \textsf{k} do not affect the value \textsf{b}. However, depending on the value of \text{m}, the code snippet in Figure~\ref{fig:chapter3:cf}(a) may have a leakage site. If the eighth bit of \textsf{m} is 1, then an attacker can also infer the eighth bit of \textsf{k} by observing the branch at line 4 or line 6. The right figure shows the corresponding machine code. It has a conditional jump instruction \textsf{jne}. The sensitive input \textsf{k} can affect the program counter (the rip register), which is the root cause of the side-channel leakages.

Figure~\ref{fig:chapter3:cf}(b) shows a different situation. While the sensitive input \textsf{k} can affect the if-else branch, the compiler removes the branch with a conditional set instruction.  The opposite situation is the same. For example, recent work tries to use bit masking to rewrite the program with control flows. However, for some situations~\cite{Coppens:2009:PMT:1607723.1608124}, compilers (e.g., GCC) optimize the code too much (from a security view) and remove the unnecessary copy by reintroducing conditional moves.
\subsubsection{Data Flow}
\begin{figure}[h]
  \begin{minipage}{0.4\linewidth}
    \begin{lstlisting}[xleftmargin=.0\textwidth, xrightmargin=.0\textwidth, frame=none]
uint8_t T[128];
...
int example3(uint8_t k, uint32_t m){
  uint32_t index = m;
  index = index + k % 128;
  uint8_t t = T[index];
  ...
}
\end{lstlisting}
  \end{minipage}
  \hfill
  \begin{minipage}{0.4\linewidth}
    \begin{lstlisting}[xleftmargin=.0\textwidth, xrightmargin=.00\textwidth, frame=none, numbers=none, mathescape=true]
...
lea    edx, [addr_T]
mov    eax, [addr_k]
and    eax, 0x7f
add    eax, [addr_m]
movzx  eax, [addr_T + eax*1]
...
\end{lstlisting}
  \end{minipage}\caption*{(a) A True Leakage}

  \begin{minipage}{0.4\linewidth}
    \begin{lstlisting}[xleftmargin=.0\textwidth, xrightmargin=.0\textwidth, frame=none]
uint8_t T[32];
...
int example4(uint8_t k, uint32_t m){
  uint32_t index = m;
  index = index + k % 32;
  uint8_t t = T[index];
  ...
}
\end{lstlisting}
  \end{minipage}
  \hfill
  \begin{minipage}{0.4\linewidth}
    \begin{lstlisting}[xleftmargin=.0\textwidth, xrightmargin=.00\textwidth, frame=none, numbers=none, mathescape=true]
...
lea    edx, [addr_T]
mov    eax, [addr_k]
and    eax, 0x3f
add    eax, [addr_m]
movzx  eax, [addr_T + eax*1]
...
\end{lstlisting}
  \end{minipage}\caption*{(b) A False Positive}
  \caption{Secret-dependent Data Accesses}\label{fig:chapter3:da}
\end{figure}

Figure~\ref{fig:chapter3:da} shows an example of the secret-dependent data access. \textsf{T} is an array with 128 elements. The size of each element is one byte. So the total size of the array is 128 Bytes. Suppose an attacker can observe the memory access at the granularity of one cache lines (64 Bytes), then it is not possible to hold all the data inside the one cache line. An attacker can get some information of the value \textsf{secret} in Figure~\ref{fig:chapter3:da}(a) by observing the cache line access. Figure~\ref{fig:chapter3:da}(b) shows a different example. In this example, only 32 different elements can be accessed in the array and the size of the array is 32 bytes, which is smaller than the size of one cache line. Depending on the base address of the array, the array can be stored in one cache line or two consecutive cache lines. Therefore, such a code may still be vulnerable to side-channel vulnerabilities. However, existing tools (e.g., CacheD) use a concrete base address. Under the circumstance, those tools may miss such vulnerabilities.

\subsection{Performance}
The second limitation of the current side-channel detection tool is the performance bottleneck, especially for those tools based on the symbolic analysis. For example, CaSym can only analyze small programs. CacheD perfroms better. However, it still can not handle large programs like RSA directly. It uses some domain knowledge to analyze only part of the program. The expensive cost comes from the symbolic execution. Symbolic execution can be used to explore all the possible paths, which is useful for many tasks. But it is significantly less likely for cache side channels bugs in crypto primitives. Cryptography primitives are more likely to have an even coverage of different paths (based on pseudo-random cipher states), and a branch-based side channel is vulnerable from the very first branch on secret data, making complex path conditions less often relevant. Therefore, we choose to analyze a trace instead of the whole path. Another bottleneck is that the IR. While the IR can significantly decrease the difficulty of the implementation, it also gives introduce an average of 10x of the overall overhead. Third, using SMT solving can be convenient because of its generality, and it is commonly used for its precision when checking branch feasibility in symbolic execution. But the decision problems that an SMT solver handles are typically at least NP-hard. On the other hand, we can use some methods to avoid the solver and find side-channel leakages in a more efficient way.

\section{Method}\label{chapter3:method}
\begin{figure}
  \centering
  \includegraphics[width=.3\columnwidth]{./figures/chapter3/attack.pdf}
  \caption{A side-channel attack}\label{fig:side-channel-attack}
\end{figure}

In the section, we give necessary definitions and notations for dealing with
programs and side-channels.

Shown in Figure~\ref{fig:side-channel-attack}, a side-channel attack can be formulated into the below steps.  A program ($\beta$) has $K$ as its sensitive input (e.g., the encryption key) and $M$ as its the public input (e.g., the plaintext). In a real execution, an adversary may have
some observations ($O$) of the program. Examples of those observations include the
timing, CPU usages, and electromagnetic signals (EM). In this dissertation, we
use secret-dependent control flows and secret-dependent data
accesses as observations.

With the above definition, we have the following mapping between $\beta$,
$K$, $M$, and $O$:
\begin{displaymath}
  \beta(K, M) \rightarrow O
\end{displaymath}


We model a side-channel in the following way. An adversary does not have
access to $K$, but he knows $\beta$, $M$, and $O$. For one execution of a
deterministic program, once $k \in K$ and $m \in M$ are fixed, the observation
($o \in O$) should also be determined. An attacker knows $\beta$, $o$,
and $m$. The attacker wants to infer the value of $k$. Moreover, we assume
an attacker can change the public input ($m \in M$) while keeping the secret input $k$.
The threat model is similar to a chosen-plaintext attack.
We now discuss how to model observations ($O$),
which are the direct information that an adversary can get during the attack.

For one execution, a program ($\beta$) has many temporary values ($t_i \in
  T$). Once $\beta$ (program), $k$ (secret), and $m$ (message, public) are
determined, $t_i$ is also fixed. Therefore, $ t_i = f_i(\beta, k, m)$, where $f_
  i$ is a function that maps between $t_i$ and ($\beta$, $k$, $m$). In the paper,
we consider two code patterns that can be exploited by an attacker,
\emph{secret-dependent control transfers} and \emph{secret-dependent data
  accesses}. In other words, an adversary has observations based on control-flows
and data accesses.

\subsection{Secret-dependent Control Transfers}
A control-flow path is secret-dependent if different input-sensitive keys
($K$) can lead to different branch conditions.
We define a branch to be secret-dependent if:
$$\exists k_{i1}, k_{i2} \in K, m \in M, \,f_i(\beta, k_{i1}, m) \neq f_i(\beta, k_{i2}, m)$$

An adversary can observe which branch the code executes if the branch condition
equals $t_b$. We use the constraint $c_i : f_i(\beta, k, m) = t_b$ to model
the observation ($o$) on secret-dependent control-transfers. Note that in the
above definition, $m$ is also a variable. So it is possible for some $m \in M$,
we can not find a pair of two different $k_{i1}$ and $k_{i2}$ to satisfy the above
inequation. For example, in the example from Figure~\ref{fig:chapter3:cf}, if $m = 0$,
the code will always execute the branch 2. However, the function \textsf{example1} still
has a secret-dependent control-flow for some $m$, so we think the code has
some side-channel leakages.


\subsection{Secret-dependent Data Accesses}
Similar to secret-dependent control-flow transfers, a data access operation is
secret-dependent if different input sensitive keys ($K$) cause access to different
memory addresses. We use the model from CacheD~\cite{203878}. The low $L$ bits
of the address are generally unimportant in side-channels.

A data access is secret-dependent if:

$$\exists k_{i1}, k_{i2} \in K, m \in M,\,f_i(\beta, k_{i1}, m) >> L \neq f_i(\beta, k_{i2}, m) >> L$$

If the memory access equals to $t_b$, we can use the constraint $c_i :
  f_i(\beta, k, m) >> L = t_b >> L$ to model the observation on secret-dependent
data accesses. Let's take a look the examples in Figure~\ref{fig:chapter3:da}(a).
Suppose the base address of the array \textsf{T} is 10. We symbolize both the $k$ and $m$. The formula that represents the memory access at line 6 is $10 + m + (k \mod 128)$. Therefore, we have the formula: $(10 + m + (k_1 \mod 128)) >> 6  \neq (10 + m + (k_2 \mod 128)) >> 6$.
Here is one possible solution: $m = 0, k_1 = 0, k_2 = 127$. In fact, for any $m$, we can always find possible $k_1$ and $k_2$ that satisfy the above inequation. It is a true leakage. The leakage can also be identified by previous tools like CacheD. Similarly, we can model the memory access at line 6 with the formula:  $10 + m + (k_1 \mod 32) >> 6  \neq 10 + m + (k_2 \mod 32) >> 6$. If $m = 0$, we can not find satisfiable $k_1$ and $k_2$ for the above inequation, which indicates that it will always access the same cache line at line 6. It is the conclusion from Cache. However, it is possible that for some $m \in M$, we can find such a pair of $k_1$ and $k_2$ ($m = 53, k_1 = 1, k_2 = 0$). If the actual public input is $0$, existing tools (e.g., CacheD) can miss such a vulnerability. On the other hand, our tool can identify the leakages precisely.

\section{Scalability}
\subsection{Trace-oriented Symbolic Execution}
Symbolic execution is notorious for its high performance cost.
Previous trace-oriented symbolic execution
work~\cite{203878,Chattopadhyay:2017:QIL:3127041.3127044} has serious
performance bottlenecks. As a result, these approaches either apply only to
small programs~\cite{Chattopadhyay:2017:QIL:3127041.3127044} or require
domain knowledge~\cite{Wang:2007:NCD:1250662.1250723} to simplify the analysis.
Those tools interpret each
instruction and update memory cells and registers with formulas that
captured the semantics of the execution and search different input values that
can lead to different execution behaviors using constraint solver.
We implement the approach presented in \S\ref{chapter3:method} and model the side-channels as formulas. While the tools can analyze some simple cases such as AES, it cannot handle complicated examples such as RSA.
We observe that finding side-channels using symbolic execution differs from
traditional symbolic execution, and it can be optimized to be as efficient
as other methods.

\subsection{Interpret Instructions Symbolically}
Existing binary analysis frameworks~\cite{shoshitaishvili2016state,
  10.1007/978-3-642-22110-1_37, song2008bitblaze} translate machine instructions into
intermediate languages (IR) to simplify analysis since
the variety of machine instructions is
enormous, and their semantics is complex. The Intel Developer
Manual~\cite{intelsys} documents more than 1000 different x86 instructions.
Unfortunately, the IR layer, which
reduces the workload of these tools, is not suitable for side-channels
analysis because
IR-based or source code side-channels analyses do not represent the executed instructions accurate enough to analyze fully their control and memory accesses.
For example, a compiler may use conditional moves or bitwise operations to eliminate
branches. Also, as some IRs are not a superset or a subset of ISA,
it is hard to rule out conditional jumps introduced by IR and add real branches
eliminated by IR transformations.

Moreover, the IR causes significant overhead~\cite{217563}.
Translating machine instructions into IR is time-consuming. For example,
REIL IR~\cite{dullien2009reil}, adopted in CacheS~\cite{236338}, has multiple
transform processes, from binary to VEX IR, BAP IR, and finally REIL IR\@.
Also, IR increases the total number of instructions. For example, x86
instruction \textit{test eax, eax} transfers into 18 REIL IR instructions.

\textbf{Our Solution:}
We abandoned IR and expended the effort to implement
symbolic execution directly on x86 instructions.
Table~\ref{scala:ir} shows that eliminating the IR reduces the number
of instructions examined during analysis. Previous works~\cite{217563} also
adopted a similar approach to speed up fuzzing. Our implementation differs
from that work in two aspects: 1) We use complete constraints. 2) We run the
symbolic execution on one execution path each time. Our approach is approximately 30 times faster than using an IR (transferring ISA into IR and
symbolically executing it).

\begin{table}%[ht]
  \centering\small\footnotesize
  \caption{The number of x86,  % instructions and the number of 
    REIL IR, and VEX IR instructions on the traces of crypto programs.}
  \label{scala:ir}
  \resizebox{.7\columnwidth}{!}{%

    \begin{tabular}{cccc}
      \hline
                        & \begin{tabular}[c]{@{}c@{}}Number of\\ x86 Instructions\end{tabular} & \begin{tabular}[c]{@{}c@{}}Number of\\ VEX IR\end{tabular} & \begin{tabular}[c]{@{}c@{}}Number of\\ REIL IR\end{tabular} \\ \hline
      AES OpenSSL 0.9.7 & $1,704$                    & $23,938$ (15x)             & $62,045$ (36x)             \\
      DES OpenSSL 0.9.7 & $2,976$                    & $41,897$ (15x)             & $100,365$ (33x)            \\
      RSA OpenSSL 0.9.7 & $1.6*10^7$                 & $2.4*10^8$ (15x)           & $5.9*10^8$ (37x)           \\
      RSA mbedTLS 2.5   & $2.2*10^7$                 & $3.1*10^8$ (15x)           & $8.6*10^8$  (39x)          \\ \hline
    \end{tabular}
  }
\end{table}

\subsection{Constraint Solving}
As discussed in the previous section, the problem of identifying
side-channels can be reduced to the question below.

\begin{quote}
  \textit{Can we find two different input variables $k_1, k_2 \in K$ that
    satisfy the formula $f_a(k_1) \neq f_a(k_2)$?}
\end{quote}

Existing approaches rely on satisfiability modulo theories (SMT) solvers
(e.g., Z3~\cite{DeMoura:2008:ZES:1792734.1792766}) to find satisfying assignments to
$k_1$ and $k_2$.
While this is a universal approach to solving constraints,
for constraints of this form, using custom
heuristics and testing is much more efficient in practice. Constraint
solving is a decision problem expressed in logic formulas. SMT solvers
transfer the SMT formula into the boolean conjunctive normal
form (CNF) and feed it into the internal boolean satisfiability
problem (SAT) solver. The translation process, called ``bit blasting'',
is time-consuming. Also, as the SAT problem is a well-known NP-complete
problem, it is hard to deal when it comes to
practical uses with huge formulas. Despite the rapid improvement
in SMT solvers in recent years, constraint solving remains one of
the obstacles to scaling the analysis of real-world crypto-systems.

\textbf{Our Solution:}
Instead of feeding the formula $f_a(k_1) \neq f_a(k_2)$ into a SMT solver, we
randomly pick $k_1, k_2 \in K$ and test them if they satisfy the
formula. Our solution is based on the following intuition. For most combination
of $(k_{1}, k_{2} )$, $f_a(k_1) \neq f_a(k_2)$. As long as
$f_a$ is not a constant function, such $k_1, k_2$ must exist. For example,
suppose each time we only have 5\% chance to find such $k_1, k_2$, then after we
test with different input combination with 100 times, we have $1 -
  (1-0.05)^{100} = 99.6\%$ chance find such $k_1, k_2$. This type of random algorithm
works well for our problem.

\section{Design and Implementation}
\subsection{Trace Logging}
The trace information can be logged via some emulators (e.g., QEMU) or dynamic binary instrumentation tools (DBI).
We run a program with the concrete input under the DBI to record execution traces.
The trace data has the following information:
\begin{itemize}
  \item Each instruction mnemonics and its memory address.
  \item The operands of each instruction and their concrete values during the runtime.
  \item The value of EFLAGS register.
  \item The memory address and the length of the sensitive information.
        Most crypto libraries stores sensitive information in arrays,
        variables or contiguous buffer.
\end{itemize}

\subsection{Instruction Level Symbolic Execution}
\label{InstructionSE}
The primary purpose of the step is to generate constraints of the input sensitive information from the execution trace. If we give the target program a new input which is different from the original input that was used to generate the execution trace but still satisfies those constraints, as an attacker, he will have the same observations on control-flow transfers and data-access patterns.

The tool runs symbolic execution on top of execution traces. At the beginning of the symbolic execution, the tool creates new symbols for each byte in the raw buffer. For other data in the register or memory at the beginning, we use actual values from the runtime information collected during the runtime. During the symbolic execution for each instruction, the tool updates every variable in the memory and registers with a math formula. The formula is made up of concrete values and the input key as the symbols accumulated through the symbolic execution.
For each formula, the tool will check weather it can be reduced into a concrete values (e.g., $k_1+12-k_1 = 12$ ). If so, the tool will only use the concrete values in the following symbolic execution.

\subsubsection{Verification and Optimization}
We run the symbolic execution (SE) on top of x86 instructions. In other words, we do not rely on any intermediate languages to simplify the implementation of symbolic execution. While the implementation itself has a lot of benefits (Better performance, accurate memory model), we need to implement the symbolic execution rules for each x86 instruction.
However, due to the complexity of x86, it is inevitable to make mistakes. Therefore, we verify the correctness of the SE engine during the execution.
The tool will collect the runtime information (Register values, memory values) and compare them with the formula generated from the symbolic execution. Whenever the tool finishes the symbolic execution of each instruction, the tool will compare the formula for each symbol and its actual value. If the two values do not match, we check the code and fix the error. Also, if the formula does not contain any symbols, the tool will use the concrete value instead of symbolic execution.

\subsubsection{Secret-dependent Control-flows}
An adversary can infer sensitive information from secret dependent control-flows. There are two kinds of control-transfer instructions: the unconditional control-transfer instructions and the conditional transfer instructions.
The unconditional instructions, like CALL, JUMP, RET transfer control from one code segment location to another. Since the transfer is independent of the input sensitive information, an attacker was not able to infer any sensitive information from the control-flow.
So the unconditional control-transfer does not leak any information based on our threat model. During the symbolic execution, we update the register information and memory cells with new formulas accordingly.

The conditional control-flow transfer instructions, like conditional jumps, depending on CPU states, may or may not transfer control flows. For conditional jumps, the CPU will test if certain condition flag
(e.g., CF = 0, ZF =1) is met and jump to certain branches, respectively.
The symbolic engine will compute the flag and represent the flag in a symbol
formula. Because we are running on a symbolic execution on an execution trace, we know which branch is executed.
If a conditional jump uses the CPU status flag, we will generate the constraint accordingly.

For examples, considering the below x86 code snippet,

\begin{lstlisting}[xleftmargin=.2\textwidth, xrightmargin=.2\textwidth]
 ...
0x0000e781      add dword [local_14h], 1
0x0000e785      cmp dword [local_14h], 4
0x0000e789      jne 0xe7df
0x0000e78b      mov dword [local_14h], 0
 ...
\end{lstlisting}

At the beginning of the instruction segment, the value at the address of local\_14h can be written as $F(\vec{K})$. At the address $e785$, the value will be updated with $F(\vec{K})+1$. Then the code compares
the value with 4 and use the result as a conditional jump. Based on the result, we can have the following formula:

$$F(\vec{K}) + 1 = 4$$

The formula, together with the memory address ($0xe789$) is store as a \textit{formula tuple (address, formula)}. Each formula tuple represents one leakage site.

\subsubsection{Secret-dependent Data Accesses}
Like input-dependent control-flow transfers, an adversary can also infer sensitive information from the data access pattern as well. We try to find this kind of leakages by checking every memory operand of the instruction. We generate the memory addressing
formulas. As discussed before, every symbols in the formula is the input key. If the formula does not contain any symbols, the memory access is independent
from the input sensitive information and will not leak any sensitive information according to our threat model. Otherwise, we will generate the constraint for
the memory addressing. We model the memory address with a symbolic formula $F(\vec{K})$. Because we also have the concrete value of the memory address $Addr1$.
Inspired by the work from~\cite{203878}, the formula can be written as:

$$F(\vec{K}) >> L = Addr1 >> L$$

$L$ represents the minimum memory address granularity that an attacker can observe. For example, Flush and Reload can distinguish between different cache lines, which means the value of L is 6.

\subsubsection{Information Flow Check}
\detect{} is designed to help software developers find and understand the side-channel vulnerabilities. To ease the procedure of fixing the bug, we also track the information flow for each byte of the input
buffer.
The step can be seen as the multiple-tag taint analysis. With the help of the information from symbolic execution, we can implement a relatively simple but relatively precise information flow track.
At the beginning of the analysis, \detect{} keep a track for each byte in
the original buffer. When \detect{} symbolically executes each instruction in the trace, it will check every value read from registers or memory. If the value is concrete, it means the instruction has nothing to do with the original buffer.
If the value is a formula, it means the original information passes through the instruction. Since each byte in the sensitive buffer is represented as a symbol with a unique ID, \detect{} can know which byte in the origin buffer goes through the instruction.

\section{Evaluation}
We evaluate our method on real-world crypto libraries, which include  OpenSSL, mbedTLS, Libgcrypt and Monocypher\@. OpenSSL is the most commonly used crypto libraries in today's software. mbedTLS\@ (previous known as PolarSSL) is designed to be easy to understand and fit on embedded devices. We also evaluate Monocypher, a new cryptographic library that resists to most side-channel attacks.
According to the developers, Monocypher is designed to have no secret dependent indices and secret dependent branches. Therefore, Monocypher should be secure under our threat model. Libgcrypt is a crytpographic library from the GunPG. As some previous work (e.g., CacheD) choose to evaluate their tools on CacheD, we can compare the evaluation results by applying the tool on Libgcrypt.

For some crypto libraries, we evaluate multiple versions. After that, we compare the evaluation results with the version history to track those leakages' patches. In summary, we evaluate our tool on the following libraries.
\begin{itemize}
  \item OpenSSL: 0.9.7, 1.0.2f, 1.0.2k, 1.1.0f, 1.1.1, 1.1.1g
  \item MbedTLS: 2.5, 2.15
  \item Libgcrypt: 1.6.1, 1.7.3, 1.8.5
  \item Monocyper: 3.0
\end{itemize}

We refer to the examples or test cases of those libraries and write simple
programs that use the crypto libraries. For symmetric encryption, the length
of the keys are 256 bit. For RSA, the length of the keys is 1024. For ECDSA, the
length of the key is 384 bit. The input public message is ``Hello World!''.
We mark variables and buffers that store a secret.
For DES and AES, we mark symmetric keys as secrets.
For RSA, we mark private keys as secrets. For ECDSA,
we mark nonces and private keys as secrets.

We build the source program into 32-bit x86 Linux executables with GCC 7.5
running on Ubuntu 16.04. While our tool can work on the stripped binaries, 
in the evaluation, we keep the debug information to get the fine-grained infromation
(e.g., line numbers).
We run our experiments on a 2.90GHz Intel Xeon(R) E5-2690 CPU with 128GB
RAM. We run the experiments simultaneously, but the execution time is calculated on a single-core.

During our evaluation process, we are interested in the following
aspects:
\begin{enumerate}
    \item Is \detect{} effective to detect side-channels in real-world crypto systems? (Effectiveness)
    \item How much performance overhead does the method introduce? (Performance)
    \item How effective are the design choices made by the tool method? (Design Choices)
\end{enumerate}

\subsection{Evaluation Result Overview}
\begin{table*}[]
  \centering\small\footnotesize
  \caption{Evaluation results overview: Algorithm, Implementation, Side-channel Leaks\,(Leaks),
    Secret-dependent Control-flows\,(CF), Secret-dependent Data-flows\,(DF),
    The number of instructions\,(\# Instructions), The Execution Time, and The Memory Usage.
  }\label{table:over_result}
  \begin{tabular}{llrrrrrr}
    \hline
    \textbf{Algorithm} & \textbf{Implementation}  & \textbf{\# Leaks} & \textbf{\# CF}    & \textbf{\# DF}
                       & \textbf{\# Instructions} & \textbf{Time}     & \textbf{RAM (MB)}                                                  \\\hline
                       &                          &                   &                   &                &             & ms              \\\cline{7-7}
    AES                & mbedTLS 2.5              & 68                & 0                 & 68             & 39,855      & 512     & 47    \\
    AES                & mbedTLS 2.15             & 68                & 0                 & 68             & 39,855      & 520     & 47    \\
    AES                & OpenSSL 0.9.7            & 75                & 0                 & 75             & 1,704       & 231     & 15    \\
    AES                & OpenSSL 1.0.2f           & 88                & 0                 & 88             & 1,350       & 36      & 15    \\
    AES                & OpenSSL 1.0.2k           & 88                & 0                 & 88             & 1,350       & 35      & 16    \\
    AES                & OpenSSL 1.1.0f           & 88                & 0                 & 88             & 1,420       & 36      & 16    \\
    AES                & OpenSSL 1.1.1            & 88                & 0                 & 88             & 1,586       & 43      & 16    \\
    DES                & mbedTLS 2.5              & 15                & 0                 & 15             & 4,596       & 58      & 8     \\
    DES                & mbedTLS 2.15             & 15                & 0                 & 15             & 4,596       & 57      & 8     \\
    DES                & OpenSSL 0.9.7            & 6                 & 0                 & 6              & 2,976       & 163     & 11    \\
    DES                & OpenSSL 1.0.2f           & 8                 & 0                 & 8              & 2,593       & 166     & 11    \\
    DES                & OpenSSL 1.0.2k           & 8                 & 0                 & 8              & 2,593       & 165     & 11    \\
    DES                & OpenSSL 1.1.0f           & 8                 & 0                 & 8              & 4,260       & 182     & 21    \\
    Triple DES         & OpenSSL 1.1.0f &  9 &0  &9   &13,105   & 369 & 56\\
    DES                & OpenSSL 1.1.1            & 6                 & 0                 & 6              & 8,272       & 229     & 43    \\
                       &                          &                   &                   &                &             & seconds         \\\cline{7-7}
    Chacha20           & Monocypher 3.0           & 0                 & 0                 & 0              & 149,353     & 2       & 15    \\
    Poly1305           & Monocypher 3.0           & 0                 & 0                 & 0              & 1,213,937   & 15      & 43    \\
    Argon2i            & Monocypher 3.0           & 0                 & 0                 & 0              & 4,595,142   & 37      & 102   \\
    Ed25519            & Monocypher 3.0           & 0                 & 0                 & 0              & 5,713,619   & 271     & 98    \\
    ECDSA              & mbedTLS 2.5              & 6                 & 6                 & 0              & 4,214,946   & 48      & 689   \\
    ECDSA              & mbedTLS 2.15             & 4                 & 4                 & 0              & 4,192,558   & 102     & 680   \\
    ECDSA              & OpenSSL 1.0.2f           & 5                 & 4                 & 1              & 8,248,322   & 101     & 980   \\
    ECDSA              & OpenSSL 1.0.2k           & 5                 & 4                 & 1              & 8,263,599   & 100     & 906   \\
    ECDSA              & OpenSSL 1.1.0f           & 5                 & 4                 & 1              & 6,100,465   & 76      & 705   \\
    ECDSA              & OpenSSL 1.1.1            & 0                 & 0                 & 0              & 10,244,076  & 121     & 1,048 \\
    ECDSA              & OpenSSL 1.1.1g           & 0                 & 0                 & 0              & 9,266,191   & 102     & 1,001 \\

                       &                          &                   &                   &                &             & minutes         \\\cline{7-7}
    RSA                & mbedTLS 2.5              & 6                 & 6                 & 0              & 22,109,246  & 39      & 3,708 \\
    RSA                & mbedTLS 2.15             & 12                & 12                & 0              & 24,484,441  & 44      & 4,012 \\
    RSA                & OpenSSL 0.9.7            & 107               & 105               & 2              & 17,002,523  & 23      & 3,601 \\
    RSA                & OpenSSL 1.0.2f           & 38                & 27                & 11             & 14,468,307  & 29      & 3,301 \\
    RSA                & OpenSSL 1.0.2k           & 36                & 27                & 9              & 15,285,210  & 40      & 3,402 \\
    RSA                & OpenSSL 1.1.0f           & 31                & 22                & 9              & 16,390,750  & 34      & 3,701 \\
    RSA                & OpenSSL 1.1.1            & 4                 & 4                 & 0              & 18,207,016  & 8       & 4,181 \\
    RSA                & OpenSSL 1.1.1g           & 8                 & 8                 & 0              & 18,536,796  & 5       & 3,901 \\
    RSA                & Libgcrypt 1.6.1          & 11                & 9                 & 2              & 9,527,231   & 2       & 2516  \\
    RSA                & Libgcrypt 1.7.3          & 14                & 14                & 0              & 10,513,606  & 14      & 2,701 \\
    RSA                & Libgcrypt 1.8.5          & 8                 & 8                 & 0              & 27,407,986  & 113     & 4,701 \\

    Total              &                          & 913               & 241               & 672            & 167,155,052 & 341m            \\\hline
  \end{tabular}
\end{table*}
Table~\ref{table:over_result} summarizes the results.
\detect{} finds 913 leaks in the crypto libraries.
Among these 913 leaks, 241 are due to secret-dependent
control-flow transfers and 672 are due to secret-dependent data accesses.

The evaluated algorithms can be classified into two categories: symmetric
encryption and asymmetric encryption. Most of the side-channel leakages in symmetric implementations are from the lookup tables. The new implementation of OpenSSL has adopted several methods (e.g., one single S-box instead of four lookup tables, smaller lookup tables) to mitigate the problem. 

We also evaluate our tool on the RSA implementation. With the optimization
introduced in the previous sections, we need not apply domain knowledge to
simplify the analysis. Our tool identifies all leakage sites
reported by CacheD~\cite{203878} and find new leaks in less time.
We also find newer versions of RSA in OpenSSL have fewer leaks. Our tool can
finish all the analysis in less than 6 hours. 

\subsection{Comparison with the Existing Tools}
\label{eval:scala}

In this section, we compare \detect{} with the
existing trace-based side-channel detection tools on vulnerability detections. For other tools, we use the data in the paper. As other tools do not quantify leakage sites, we only include the time of detecting vulnerabilities to perform a fair comparison.

The comparison result with CacheD~\cite{203878} is shown in Table~\ref{eval:cacheD}.
Note that one statement in the source code can be compiled into several machine instructions. So it is possible that one statement can have multiple leakage points. Under the circumstance, we think it is only a leakage.
We have confirmed that \detect{} can identify all the secret-dependent data access vulnerabilities reported by CacheD. In addition, \detect{} finds many new ones.
CacheD fails to detect some vulnerabilities for two
reasons. First, CacheD can only detect secret-dependent data access
vulnerabilities. \detect{} can detect secret-dependent control-flows as well.
Second, according to the CacheD paper, CacheD times out after 20 hours to process
asymmetric ciphers. CacheD applies some domain knowledge to simplify and speed up
the analysis.
While those optimizations do not introduce false positives, they may miss some
vulnerabilities.
Third, CacheD only symbolizes the encryption keys. Some side-channel leakages when the input messages equal to some certain values. It is possible that CacheD miss some
leakages as we have discussion the previous sections.
We notice that the number of instructions in those traces are different due to the different analysis starting functions and building options during the evaluation.
Table~\ref{eval:cacheD} shows that
\detect{} is faster than CacheD. \detect{} is much faster than CacheD when analyzing the same
number of instructions. For example, when we test~\detect{} on AES from OpenSSL
0.9.7, \detect{} is over 100x faster than CacheD.
\begin{table*}[]
 \centering
  \caption{Comparison with CacheD: Time,
    Secret-dependent Control-flows\,(CF), Secret-dependent Data-flows\,(DF), The Number of Instructions\,(\# Instructions).}
  \label{eval:cacheD}

    \begin{tabular}{@{}l|r@{~~}r@{~~}r|r@{~~}r@{~}r@{}}
      \hline
      \multicolumn{1}{l|}{} & \multicolumn{3}{c|}{CacheD} & \multicolumn{3}{c}{Abacus}                                             \\
      Name                  & Time (s)                    & \# Instructions            & DF & Time (s) & \# Instructions & CF+DF   \\ \hline
      AES OpenSSL 0.9.7         & 43.4                        & 791                        & 48 & 0.23     & 1,704           & 0+75    \\
      AES OpenSSL 1.0.2f       & 48.5                        & 2,410                      & 32 & 0.04     & 1,350           & 0+88    \\
      RSA OpenSSL 0.9.7       & 199.3                       & 674,797                    & 1  & 1,351.6  & 17,002,523      & 105+2   \\
      RSA OpenSSL 1.0.2f     & 165.6                       & 473,392                    & 1  & 1,753.3  & 14,468,307      & 27+11   \\
      RSA Libgcrypt 1.6.1     & 11542.3                     & 26,848,103                 & 2  & 128.1    & 9,527,231       & 9+2     \\
      RSA Libgcrypt 1.7.3         & 10788.9                     & 27,775,053                 & 0  & 891.7    & 10,513,606      & 14+0    \\ \hline
      Total                 & 22,788.0                    & 55,738,546                 & 84 & 4,125.0  & 51,514,721      & 155+178 \\ \hline
      \multicolumn{7}{l}{\# of Instructions per second \qquad  CacheD: 2,445 \qquad \tool: 12,489}                                 \\ \hline
    \end{tabular}

\end{table*}

DATA~\cite{217537} identifies
side-channel leakages by finding differences in execution traces of
the test program under \emph{various secret inputs}. According to
the original DATA paper, it uses 443 different traces to analyze the
side-channel vulnerabilities in symmetric cyphers and 450 different
traces to analyze the side-channel vulnerabilities in asymmetric
cyphers. On the other hand, \detect{} detects side-channel
vulnerabilities from one execution trace. \detect{} uses symbolic
analysis to extract formulas that model each side-channel
leakage. After that, we sample the formula with \emph{various
  secret inputs} to detect and quantify each leakage site. In
theory, DATA might have better code coverage than \detect{} because it
uses more execution traces,  but \detect{} has the following
advantages. a) \detect{} is faster than DATA. For example, it takes
116 minutes for DATA to detect vulnerabilities in the RSA implementation in OpenSSL 1.1.0f\@. \detect{} only spends 34 minutes, as shown in Table~\ref{table:over_result}. It takes 13 minutes and 20 minutes
for DATA to analyze the side-channel leakages in AES and DES,
respectively. On the other hand, \detect{} finishes its analysis in
less than ten seconds while finding all the leakages reported by
DATA. b) Because \detect{} does not run the test program again when wedinghao w
have a new \emph{secret input}, \detect{} can test more input secrets
on those formulas within the same time to achieve better precision.
c) DATA tries to use leakage models (domain knowledge) to classify each leakage.
The strength of Abacus is that it does not need such domain knowledge.
DATA reports 278 control-flow and 460 memory-access leaks for the RSA implementation in OpenSSL 1.1.0f. Among those leakages, they find one new vulnerability in RSA after some manual analysis.
\detect{} finds the vulnerability.  For each leakage site, \detect{} can provide
concrete examples to trigger the issue and give an estimation to
assess the severity level of the vulnerability.

\subsection{Case Studies}
\subsubsection{DES and AES}
Our tool confirms that both implementations in OpenSSL and mbedTLS have side-channel leakages
sites. Moreover, we find that all the leakages belong to the secret-dependent data accesses. The reference implementation of AES uses four lookup tables to speed up the computation. However, such implementation are vulnerable to side-channel attacks. Previous work has shown an end-to-end attack to fully recover the key. Our findings is similar to the previous work. We also notice that later version of OpenSSL (after 1.0.1) uses a modified version with smaller S-table. However, \detect{} also find the leakage sites in the version. Recent work also finds the sites through theoretical analysis.

\subsubsection{RSA}
We also evaluates our tool on the RSA implementations. With the optimizations
introduced in the previous section, we do not apply any domain knowledge to
simplify the analysis. Therefore, our tools can identify all the leakage sites
reported by CacheD~\cite{203878} in a shorter time. Our tool finds that most
leakages in RSA occur in the big number implementation. We also find the newer
versions of RSA in OpenSSL tend to have fewer leakages detected by \detect{}. 

Even for the up-to-date version of OpenSSL, \detect{} still find several
side-channel leakages. Figure~\ref{chapter3:fig:unknown_leakage} shows an unknown leakage site in OpenSSL 1.1.1. It is a secret-dependent control flow transfers. 
However, as the branch is inside a loop and a bit shift function causes the branch leak different bits from the sensitive buffer.

\begin{figure}[h]
\centering
\begin{lstlisting}[xleftmargin=.02\textwidth,xrightmargin=.01\textwidth]
while (!BN_is_bit_set(B, shift)) { /* note that 0 < B */
    shift++;
    if (BN_is_odd(X)) {
        if (!BN_uadd(X, X, n))
            goto err;
    }
    ...
    if (!BN_rshift1(X, X))  // It causes the leak severe!
        goto err;
    ...
}
\end{lstlisting}
    \caption{Unknown sensitive secret-dependent branch leaks from function 
             \textsf{int\_bn\_mod\_inverse} in OpenSSL 1.1.1. The function can leak the last digit from big number \textbf{X}. However, the leak is more severe because of the 
             function \textsf{BN\_rshift1}. Each time function \textsf{BN\_rshift1}
             will shift \textbf{X} right by one and places the result in \textbf{X}. Therefore,
             an attacker can infer multiple bits of \textbf{X} by observing the branch at line 3.}
    \label{chapter3:fig:unknown_leakage}
\end{figure}


\subsubsection{Monocypher}\label{eval:mono}
Monocypher is a small, easy to use cryptographic library with
performance comparable to LibSodium~\cite{libsodium} and NaCl~\cite{bernstein2012security}.
We choose four ciphers that are
designed to be side-channel resistant from the library.
Because those ciphers have no
data flow from secrets to branch conditions and load addresses.
Monocypher should be safe under our threat models.
We analyze those ciphers with \detect{}, and it reports no leaks.
This indicates that \detect{} is effective for validating countermeasures.

\section{Discussion}


\detect{} works on native x86 execution traces. The design, which is very precise in terms of true leakages compared to other static source code method~\cite{197207,BacelarAlmeida:2013:FVS:2483313.2483334}, also has the common limitations of dynamic approaches. \detect{} may only cover part of the code. Each time we only get one single execution trace. Therefore, we may neglect some side-channel vulnerabilities not covered by the traces analyzed.However, this is not a crucial problem for analyzing cryptographic libraries, because cryptographic libraries are designed to have the same code coverage for various inputs. Our evaluation also confirms the above point. For symmetric encryption, during our evaluation there is no secret-dependent control-flow transfers. RSA implementations have several secret-dependent control-flow transfers. Most of them are bound checks, which do not leak much information and have negligible effects on the whole code coverage as well.

While recent works have reported lots of potential side-channel vulnerabilities, most of them are not patched by developers. The DES implementation of OpenSSL has several sensitive leakages, but given the end life status of DES, it is still unpatched for the worth of engineering effort. After we manually analyze those leakage sites, we find many of them leak very little or useless information (e.g., the length of big numbers), which partially explain why developers are not interested in fix all the leakages. 

We use a sampling method to detect side-channel leakages. The sampling method seems simple and may miss some leakages in theory. However, the evaluation result shows \detect{} can identify all leakages found by the previous work~\cite{203878,236338,Brotzman19Casym}.
